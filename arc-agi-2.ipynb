{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:54.700396Z",
     "start_time": "2025-08-10T21:15:54.686170Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html\"\"\"",
   "id": "99552829481bfb28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.614455Z",
     "start_time": "2025-08-10T21:15:54.776465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse, json, os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import warnings\n",
    "\n",
    "import time, multiprocessing\n",
    "import multiT_sys\n",
    "import layers\n",
    "import init\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ],
   "id": "4c1ade1759529ed0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.742776Z",
     "start_time": "2025-08-10T21:15:59.624108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ARCVisualizer:\n",
    "    \"\"\"Enhanced ARC task vis w/ mult display modes\n",
    "\n",
    "    provides utilities for conv int grids to RGB images, w/ optionality\n",
    "    to add grid liones/titles and assmbling comp. vis of trainig and test pairs \"\"\"\n",
    "\n",
    "    PALETTE = np.array([\n",
    "        [0,   0,   0],      #0 black\n",
    "        [0,   116, 217],    #1 blue\n",
    "        [255, 65,  54],     #2 red\n",
    "        [46,  204, 64],     #3 green\n",
    "        [255, 220, 0],      #4 yellow\n",
    "        [128, 128, 128],    #5 gray\n",
    "        [240, 18,  190],    #6 magenta/pink\n",
    "        [255, 133, 27],     #7 orange\n",
    "        [0,   255, 255],    #8 cyan/sky\n",
    "        [135, 12,  37],     #9 maroon/brown\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "    def __init__(self, scale: int = 30, draw_grid: bool = True):\n",
    "        self.scale = scale\n",
    "        self.draw_grid = draw_grid\n",
    "        self.cmap = colors.ListedColormap([\n",
    "            \"#000000\", \"#0074D9\", \"#FF4136\", \"#2ECC40\", \"#FFDC00\",\n",
    "            \"#AAAAAA\", \"#F012BE\", \"#FF851B\", \"#7FDBFF\", \"#870C25\"])\n",
    "        self.norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    def grid_to_image(self, grid: Union[List[List[int]], np.ndarray],\n",
    "                      title: str = None) -> Image.Image:\n",
    "        \"\"\"conv grid to PIL image w/ optional title\n",
    "\n",
    "        input grid must be 2d-list or np array w/ 0-9 ints inclusive\n",
    "\n",
    "        returns nearest-neighbor resize to enlarge each cell by config scale\"\"\"\n",
    "        arr = np.array(grid, dtype=np.int16)\n",
    "        if arr.ndim != 2:\n",
    "            raise ValueError(\"Grid must be 2D\")\n",
    "        if arr.min() < 0 or arr.max() > 9:\n",
    "            raise ValueError(\"Grid values must be in 0-9 inclusive\")\n",
    "        rgb = self.PALETTE[arr]\n",
    "        img = Image.fromarray(rgb.astype(np.uint8), mode=\"RGB\")\n",
    "        if self.scale != 1:\n",
    "            img = img.resize((img.width * self.scale, img.height * self.scale),\n",
    "                             resample=Image.NEAREST)\n",
    "        if self.draw_grid and self.scale >= 10:\n",
    "            self._add_gridlines(img)\n",
    "        if title:\n",
    "            img = self._add_title_banner(img, title)\n",
    "        return img\n",
    "    def _add_gridlines(self, img: Image.Image):\n",
    "        \"\"\"draw grid lines on image\"\"\"\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        grid_color = (40, 40, 40)\n",
    "        for x in range(0, img.width + 1, self.scale):\n",
    "            draw.line([(x, 0), (x, img.height)], fill=grid_color)\n",
    "        for y in range(0, img.height + 1, self.scale):\n",
    "            draw.line([(0, y), (img.width, y)], fill=grid_color)\n",
    "\n",
    "    def _add_title_banner(self, img: Image.Image, title: str) -> Image.Image:\n",
    "        \"\"\"prepend small banner w/ title above image\"\"\"\n",
    "        banner_height = 30\n",
    "        padding = 5\n",
    "        new_img = Image.new(\"RGB\", (img.width, banner_height + padding + img.height),\n",
    "                            (255, 255, 255))\n",
    "        draw = ImageDraw.Draw(new_img)\n",
    "        draw.rectangle([0, 0, img.width, banner_height], fill=(245, 245, 245))\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 14)\n",
    "        except Exception:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((10, 8), title, fill=(30, 30, 30), font=font)\n",
    "        new_img.paste(img, (0, banner_height + padding))\n",
    "        return new_img\n",
    "\n",
    "    def visualize_task_matplotlib(self, task: Dict, task_id: str = None, \n",
    "                                  show_predictions: List = None):\n",
    "        \"\"\"vis full task using matplotlib\n",
    "\n",
    "        training and test pairs arr in grid of subplots.  \n",
    "        if predictions shown next to corresponding test inputs if provided\n",
    "          Unused axes are hidden +  returned figure can be\n",
    "        saved or further customized by caller\n",
    "        \"\"\"\n",
    "        n_train = len(task[\"train\"])\n",
    "        n_test = len(task[\"test\"])\n",
    "        n_rows = max(2, n_test + (1 if show_predictions else 0))\n",
    "        n_cols = max(n_train, 2)\n",
    "        fig, axes = plt.subplots(n_rows, n_cols * 2, figsize=(n_cols * 4, n_rows * 2))\n",
    "        if n_rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        #plot training examples\n",
    "        for i, example in enumerate(task[\"train\"]):\n",
    "            ax_in = axes[0, i * 2]\n",
    "            ax_out = axes[0, i * 2 + 1]\n",
    "            ax_in.imshow(example[\"input\"], cmap=self.cmap, norm=self.norm)\n",
    "            ax_in.set_title(f\"Train {i+1} Input\")\n",
    "            ax_in.axis(\"off\")\n",
    "            ax_in.grid(True, which=\"both\", color=\"lightgrey\", linewidth=0.5)\n",
    "            ax_out.imshow(example[\"output\"], cmap=self.cmap, norm=self.norm)\n",
    "            ax_out.set_title(f\"Train {i+1} Output\")\n",
    "            ax_out.axis(\"off\")\n",
    "            ax_out.grid(True, which=\"both\", color=\"lightgrey\", linewidth=0.5)\n",
    "        #plot test inputs\n",
    "        for i, test in enumerate(task[\"test\"]):\n",
    "            ax = axes[1, i * 2]\n",
    "            ax.imshow(test[\"input\"], cmap=self.cmap, norm=self.norm)\n",
    "            ax.set_title(f\"Test {i+1} Input\")\n",
    "            ax.axis(\"off\")\n",
    "            ax.grid(True, which=\"both\", color=\"lightgrey\", linewidth=0.5)\n",
    "        #plot predictions if provided\n",
    "        if show_predictions:\n",
    "            for i, pred in enumerate(show_predictions):\n",
    "                if i < n_test:\n",
    "                    ax = axes[1, i * 2 + 1]\n",
    "                    ax.imshow(pred, cmap=self.cmap, norm=self.norm)\n",
    "                    ax.set_title(f\"Test {i+1} Prediction\")\n",
    "                    ax.axis(\"off\")\n",
    "                    ax.grid(True, which=\"both\", color=\"lightgrey\", linewidth=0.5)\n",
    "        #hide unused subplots\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols * 2):\n",
    "                idx = i * n_cols * 2 + j\n",
    "                if idx >= len(axes.flat):\n",
    "                    continue\n",
    "                if i == 0 and j >= n_train * 2:\n",
    "                    axes[i, j].axis(\"off\")\n",
    "                elif i == 1 and j >= n_test * 2:\n",
    "                    axes[i, j].axis(\"off\")\n",
    "        if task_id:\n",
    "            fig.suptitle(f\"Task: {task_id}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def create_composite_image(self, task: Dict, task_id: str = None,\n",
    "                               solutions: List = None) -> Image.Image:\n",
    "        \"\"\"generate composite image for all training and test pairs.\n",
    "\n",
    "        Training examples are displayed as input/output pairs\n",
    "        test inputs are optionally paired w/ provided solutions\n",
    "        Images stacked vert to produce single overview of entire task.\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        #Training pairs\n",
    "        for i, example in enumerate(task[\"train\"]):\n",
    "            in_img = self.grid_to_image(example[\"input\"], f\"Train {i+1} Input\")\n",
    "            out_img = self.grid_to_image(example[\"output\"], f\"Train {i+1} Output\")\n",
    "            pair = self._hstack([in_img, out_img], gap=10)\n",
    "            images.append(pair)\n",
    "        #Test inputs and solutions\n",
    "        for i, test in enumerate(task[\"test\"]):\n",
    "            test_img = self.grid_to_image(test[\"input\"], f\"Test {i+1} Input\")\n",
    "            if solutions and i < len(solutions):\n",
    "                sol_img = self.grid_to_image(solutions[i], f\"Test {i+1} Solution\")\n",
    "                pair = self._hstack([test_img, sol_img], gap=10)\n",
    "                images.append(pair)\n",
    "            else:\n",
    "                images.append(test_img)\n",
    "        composite = self._vstack(images, gap=15)\n",
    "        if task_id:\n",
    "            composite = self._add_title_banner(composite, f\"Task: {task_id}\")\n",
    "        return composite\n",
    "\n",
    "    def _hstack(self, images: List[Image.Image], gap: int = 10) -> Image.Image:\n",
    "        \"\"\"horz stack list of images w/ optional gaps\"\"\"\n",
    "        if not images:\n",
    "            raise ValueError(\"No images to stack\")\n",
    "        height = max(img.height for img in images)\n",
    "        width = sum(img.width for img in images) + gap * (len(images) - 1)\n",
    "        result = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
    "        x = 0\n",
    "        for img in images:\n",
    "            result.paste(img, (x, 0))\n",
    "            x += img.width + gap\n",
    "        return result\n",
    "\n",
    "    def _vstack(self, images: List[Image.Image], gap: int = 10) -> Image.Image:\n",
    "        \"\"\"vert stack list of images w/ optional gaps\"\"\"\n",
    "        if not images:\n",
    "            raise ValueError(\"No images to stack\")\n",
    "        width = max(img.width for img in images)\n",
    "        height = sum(img.height for img in images) + gap * (len(images) - 1)\n",
    "        result = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
    "        y = 0\n",
    "        for img in images:\n",
    "            x = (width - img.width) // 2  #center horizontally\n",
    "            result.paste(img, (x, y))\n",
    "            y += img.height + gap\n",
    "        return result"
   ],
   "id": "857ace08af609002",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.766667Z",
     "start_time": "2025-08-10T21:15:59.752018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DSLOperations:\n",
    "    \"\"\"coll of pure funcs to manip int grids\n",
    "    \n",
    "    ops form building blocks of symbolic search + incl basic geo transforms(rot, flip trans), color repl, cropping, padding, flood filling and symm checks\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate(grid: np.ndarray, k: int = 1) -> np.ndarray:\n",
    "        \"\"\"rotate grid by 90 deg * k steps using np.rot90\"\"\"\n",
    "        return np.rot90(grid, k)\n",
    "\n",
    "    @staticmethod\n",
    "    def flip(grid: np.ndarray, axis: int = 0) -> np.ndarray:\n",
    "        \"\"\"flip grid along vert (axis=0) or horz (axis=1) axis\"\"\"\n",
    "        return np.flip(grid, axis=axis)\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose(grid: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"swap x and y axes of grid\"\"\"\n",
    "        return np.swapaxes(grid, 0, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def color_replace(grid: np.ndarray, from_color: int, to_color: int) -> np.ndarray:\n",
    "        \"\"\"repl all occ of from_color w/ to_color\"\"\"\n",
    "        result = grid.copy()\n",
    "        result[result == from_color] = to_color\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def crop(grid: np.ndarray, x1: int, y1: int, x2: int, y2: int) -> np.ndarray:\n",
    "        \"\"\"extr rectangular subgrid defined by (x1,y1) to (x2,y2) inclusive\"\"\"\n",
    "        return grid[y1:y2+1, x1:x2+1]\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(grid: np.ndarray, top: int = 0, bottom: int = 0,\n",
    "            left: int = 0, right: int = 0, fill: int = 0) -> np.ndarray:\n",
    "        \"\"\"pad grid on all sides w/ specified count of rows/columns\"\"\"\n",
    "        return np.pad(grid, ((top, bottom), (left, right)), constant_values=fill)\n",
    "\n",
    "    @staticmethod\n",
    "    def flood_fill(grid: np.ndarray, x: int, y: int, new_color: int) -> np.ndarray:\n",
    "        \"\"\"perf flood fill starting at (x,y) using new color\"\"\"\n",
    "        grid = grid.copy()\n",
    "        target_color = grid[y, x]\n",
    "        if target_color == new_color:\n",
    "            return grid\n",
    "        h, w = grid.shape\n",
    "        stack = [(x, y)]\n",
    "        while stack:\n",
    "            cx, cy = stack.pop()\n",
    "            if cx < 0 or cy < 0 or cx >= w or cy >= h:\n",
    "                continue\n",
    "            if grid[cy, cx] != target_color:\n",
    "                continue\n",
    "            grid[cy, cx] = new_color\n",
    "            stack.extend([(cx+1, cy), (cx-1, cy), (cx, cy+1), (cx, cy-1)])\n",
    "        return grid\n",
    "\n",
    "    @staticmethod\n",
    "    def bounding_box(grid: np.ndarray, color: int) -> Optional[Tuple[int, int, int, int]]:\n",
    "        \"\"\"ret bounding box of all cells matching given color\"\"\"\n",
    "        yx = np.argwhere(grid == color)\n",
    "        if len(yx) == 0:\n",
    "            return None\n",
    "        ys, xs = yx[:, 0], yx[:, 1]\n",
    "        return np.min(xs), np.min(ys), np.max(xs), np.max(ys)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_object(grid: np.ndarray, color: int,\n",
    "                       background: int = 0) -> Optional[np.ndarray]:\n",
    "        \"\"\"extract smallest subgrid containing specified color\"\"\"\n",
    "        bbox = DSLOperations.bounding_box(grid, color)\n",
    "        if bbox is None:\n",
    "            return None\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return grid[y1:y2+1, x1:x2+1]\n",
    "\n",
    "    @staticmethod\n",
    "    def count_colors(grid: np.ndarray) -> Dict[int, int]:\n",
    "        \"\"\"count occurrences of each color in grid\"\"\"\n",
    "        unique, counts = np.unique(grid, return_counts=True)\n",
    "        return dict(zip(unique, counts))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_symmetry(grid: np.ndarray) -> Dict[str, bool]:\n",
    "        \"\"\"return dict indicating presence of various symmetries\"\"\"\n",
    "        return {\n",
    "            \"horizontal\": np.array_equal(grid, np.flipud(grid)),\n",
    "            \"vertical\": np.array_equal(grid, np.fliplr(grid)),\n",
    "            \"diagonal\": np.array_equal(grid, grid.T),\n",
    "            \"rotational_90\": np.array_equal(grid, np.rot90(grid, 2))\n",
    "        }\n",
    "\n",
    "\n"
   ],
   "id": "774a5216151a7015",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.792240Z",
     "start_time": "2025-08-10T21:15:59.776945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataAugmentation:\n",
    "    \"\"\"generate simple augmented versions of given ARC task.\n",
    "\n",
    "    Augmentations include transpose, rotations and random color permutations\n",
    "    variants can expose novel patterns to symbolic search or\n",
    "    neural models and potentially improve generalization\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_task(task: Dict, include_transpose: bool = True,\n",
    "                    include_rotation: bool = True,\n",
    "                    include_color_permutation: bool = True) -> List[Dict]:\n",
    "        \"\"\"ret list containing original task and its augmentations\"\"\"\n",
    "        augmented = [task]\n",
    "        if include_transpose:\n",
    "            augmented.append(DataAugmentation._transpose_task(task))\n",
    "        if include_rotation:\n",
    "            for k in [1, 2, 3]:\n",
    "                augmented.append(DataAugmentation._rotate_task(task, k))\n",
    "        if include_color_permutation:\n",
    "            perm = DataAugmentation._generate_color_permutation()\n",
    "            augmented.append(DataAugmentation._permute_colors_task(task, perm))\n",
    "        return augmented\n",
    "\n",
    "    @staticmethod\n",
    "    def _transpose_task(task: Dict) -> Dict:\n",
    "        \"\"\"ret new task w/ all grids transposed\"\"\"\n",
    "        new_task = {'train': [], 'test': []}\n",
    "        for example in task['train']:\n",
    "            new_task['train'].append({\n",
    "                'input': np.transpose(example['input']).tolist(),\n",
    "                'output': np.transpose(example['output']).tolist()\n",
    "            })\n",
    "        for test in task['test']:\n",
    "            new_task['test'].append({\n",
    "                'input': np.transpose(test['input']).tolist()\n",
    "            })\n",
    "        return new_task\n",
    "\n",
    "    @staticmethod\n",
    "    def _rotate_task(task: Dict, k: int) -> Dict:\n",
    "        \"\"\"ret new task w/ all grids rotated by 90 deg * k\"\"\"\n",
    "        new_task = {'train': [], 'test': []}\n",
    "        for example in task['train']:\n",
    "            new_task['train'].append({\n",
    "                'input': np.rot90(example['input'], k).tolist(),\n",
    "                'output': np.rot90(example['output'], k).tolist()\n",
    "            })\n",
    "        for test in task['test']:\n",
    "            new_task['test'].append({\n",
    "                'input': np.rot90(test['input'], k).tolist()\n",
    "            })\n",
    "        return new_task\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_color_permutation() -> np.ndarray:\n",
    "        \"\"\"Generate random permutation of colors, preserving background\"\"\"\n",
    "        perm = np.arange(10)\n",
    "        perm[1:] = np.random.permutation(9) + 1\n",
    "        return perm\n",
    "\n",
    "    @staticmethod\n",
    "    def _permute_colors_task(task: Dict, permutation: np.ndarray) -> Dict:\n",
    "        \"\"\"Apply color permutation to all grids in task\"\"\"\n",
    "        new_task = {'train': [], 'test': []}\n",
    "        for example in task['train']:\n",
    "            new_task['train'].append({\n",
    "                'input': permutation[np.array(example['input'])].tolist(),\n",
    "                'output': permutation[np.array(example['output'])].tolist()\n",
    "            })\n",
    "        for test in task['test']:\n",
    "            new_task['test'].append({\n",
    "                'input': permutation[np.array(test['input'])].tolist()\n",
    "            })\n",
    "        return new_task\n",
    "\n"
   ],
   "id": "6e7b76f58a2cde3e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.815335Z",
     "start_time": "2025-08-10T21:15:59.803359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SymbolicProgramSearch:\n",
    "    \"\"\"search space of small prog composed of DSL ops\n",
    "\n",
    "    DFS used to explore comp of primitive ops - when prog transforms all training\n",
    "    inputs to corr. outputs, deemed VALID solution - max prog depth can be config at instantiation\"\"\"\n",
    "    def __init__(self, max_depth: int = 3):\n",
    "        self.max_depth = max_depth\n",
    "        self.dsl = DSLOperations()\n",
    "        #define candidate ops as (name, function) pairs\n",
    "        self.operations = [\n",
    "            (\"rotate_90\", lambda g: self.dsl.rotate(g, 1)),\n",
    "            (\"rotate_180\", lambda g: self.dsl.rotate(g, 2)),\n",
    "            (\"rotate_270\", lambda g: self.dsl.rotate(g, 3)),\n",
    "            (\"flip_h\", lambda g: self.dsl.flip(g, 1)),\n",
    "            (\"flip_v\", lambda g: self.dsl.flip(g, 0)),\n",
    "            (\"transpose\", lambda g: self.dsl.transpose(g)),\n",
    "        ]\n",
    "        #include simple color replacements for first few colors\n",
    "        for i in range(1, 4):\n",
    "            for j in range(1, 4):\n",
    "                if i != j:\n",
    "                    self.operations.append(\n",
    "                        (f\"color_{i}_to_{j}\", lambda g, fi=i, fj=j: self.dsl.color_replace(g, fi, fj))\n",
    "                    )\n",
    "\n",
    "\n",
    "    def search(self, task: Dict) -> Optional[List[Tuple[str, Any]]]:\n",
    "        \"\"\"attempt to discover program that solves training examples\"\"\"\n",
    "        train_examples = task[\"train\"]\n",
    "        return self._dfs_search(train_examples, [])\n",
    "\n",
    "    def _dfs_search(self, examples: List[Dict],\n",
    "                    current_program: List[Tuple[str, Any]]) -> Optional[List[Tuple[str, Any]]]:\n",
    "        \"\"\"DFS for program that matches all training pairs\"\"\"\n",
    "        if len(current_program) > self.max_depth:\n",
    "            return None\n",
    "        #check current program\n",
    "        if current_program and self._program_matches(examples, current_program):\n",
    "            return current_program\n",
    "        #explore further operations\n",
    "        for op_name, op_func in self.operations:\n",
    "            new_program = current_program + [(op_name, op_func)]\n",
    "            result = self._dfs_search(examples, new_program)\n",
    "            if result is not None:\n",
    "                return result\n",
    "        return None\n",
    "\n",
    "    def _program_matches(self, examples: List[Dict],\n",
    "                         program: List[Tuple[str, Any]]) -> bool:\n",
    "        \"\"\"check whether candidate prog produces all expected outputs\"\"\"\n",
    "        for example in examples:\n",
    "            input_grid = np.array(example[\"input\"])\n",
    "            expected_output = np.array(example[\"output\"])\n",
    "            result = self._apply_program(input_grid, program)\n",
    "            if result is None or not np.array_equal(result, expected_output):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _apply_program(self, grid: np.ndarray,\n",
    "                       program: List[Tuple[str, Any]]) -> Optional[np.ndarray]:\n",
    "        \"\"\"apply seq of ops to grid\"\"\"\n",
    "        try:\n",
    "            result = grid.copy()\n",
    "            for _, op_func in program:\n",
    "                result = op_func(result)\n",
    "            return result\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def apply(self, grid: np.ndarray,\n",
    "              program: List[Tuple[str, Any]]) -> Optional[np.ndarray]:\n",
    "        \"\"\"apply discovered program to new grid\"\"\"\n",
    "        return self._apply_program(grid, program)"
   ],
   "id": "6141347b812142c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.833069Z",
     "start_time": "2025-08-10T21:15:59.825038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleARCNet(nn.Module):\n",
    "    \"\"\"light cnn for recog grid patterns\n",
    "\n",
    "    net takes one-hot input and output grids stacked along channel dim and predicts one of\n",
    "    transform labels - NOT TRAINED YET - simple building base\"\"\"\n",
    "    def __init__(self, max_grid_size: int = 30, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.max_grid_size = max_grid_size\n",
    "        #encoder: two conv layers w/ pooling and adaptive pooling to fixed size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(20, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(4)\n",
    "        )\n",
    "        #fully connected classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_grid: torch.Tensor, output_grid: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass: classify relation between input and output grid\"\"\"\n",
    "        x = torch.cat([input_grid, output_grid], dim=1)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_to_tensor(grid: np.ndarray, num_colors: int = 10,\n",
    "                       max_size: int = 30) -> torch.Tensor:\n",
    "        \"\"\"conv an integer grid to one‑hot tensor w/ padding\"\"\"\n",
    "        h, w = grid.shape\n",
    "        padded = np.zeros((max_size, max_size), dtype=int)\n",
    "        padded[:h, :w] = grid\n",
    "        one_hot = np.zeros((num_colors, max_size, max_size), dtype=np.float32)\n",
    "        for i in range(num_colors):\n",
    "            one_hot[i] = (padded == i).astype(np.float32)\n",
    "        return torch.tensor(one_hot)"
   ],
   "id": "bf1ae6e42e50c5b0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.856578Z",
     "start_time": "2025-08-10T21:15:59.841902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ARCCompressor:\n",
    "    \"\"\"\n",
    "    main model class for VAE Decoder in ARC soln\n",
    "    \"\"\"\n",
    "\n",
    "    #def channel dimensions that all layers use\n",
    "    n_layers = 4\n",
    "    share_up_dim = 16\n",
    "    share_down_dim = 8\n",
    "    decoding_dim = 4\n",
    "    softmax_dim = 2\n",
    "    cummax_dim = 4\n",
    "    shift_dim = 4\n",
    "    nonlinear_dim = 16\n",
    "\n",
    "    # This function gives channel dimension of residual stream depending on\n",
    "    # which dimensions are present, for every tensor in multitensor.\n",
    "    def channel_dim_fn(self, dims):\n",
    "        return 16 if dims[2] == 0 else 8\n",
    "\n",
    "    def __init__(self, task):\n",
    "        \"\"\"\n",
    "        Create model that is tailored to given task, and initialize all weights.\n",
    "        weights are symmetrized such that swapping x and y dimension ordering should\n",
    "        make output's dimension ordering also swapped, for same weights. This may not\n",
    "        be exactly correct since symmetrizing all operations is difficult.\n",
    "        Args:\n",
    "            task (preprocessing.Task): task which model is to be made for solving.\n",
    "        \"\"\"\n",
    "        self.multitensor_system = task.multitensor_system\n",
    "\n",
    "        # Initialize weights\n",
    "        initializer = init.Initializer(self.multitensor_system, self.channel_dim_fn)\n",
    "\n",
    "        self.multiposteriors = initializer.initialize_multiposterior(self.decoding_dim)\n",
    "        self.decode_weights = initializer.initialize_multilinear([self.decoding_dim, self.channel_dim_fn])\n",
    "        initializer.symmetrize_xy(self.decode_weights)\n",
    "        self.target_capacities = initializer.initialize_multizeros([self.decoding_dim])\n",
    "\n",
    "        self.share_up_weights = []\n",
    "        self.share_down_weights = []\n",
    "        self.softmax_weights = []\n",
    "        self.cummax_weights = []\n",
    "        self.shift_weights = []\n",
    "        self.direction_share_weights = []\n",
    "        self.nonlinear_weights = []\n",
    "\n",
    "        for layer_num in range(self.n_layers):\n",
    "            self.share_up_weights.append(initializer.initialize_multiresidual(self.share_up_dim, self.share_up_dim))\n",
    "            self.share_down_weights.append(initializer.initialize_multiresidual(self.share_down_dim, self.share_down_dim))\n",
    "            output_scaling_fn = lambda dims: self.softmax_dim * (2 ** (dims[1] + dims[2] + dims[3] + dims[4]) - 1)\n",
    "            self.softmax_weights.append(initializer.initialize_multiresidual(self.softmax_dim, output_scaling_fn))\n",
    "            self.cummax_weights.append(initializer.initialize_multiresidual(self.cummax_dim, self.cummax_dim))\n",
    "            self.shift_weights.append(initializer.initialize_multiresidual(self.shift_dim, self.shift_dim))\n",
    "            self.direction_share_weights.append(initializer.initialize_multidirection_share())\n",
    "            self.nonlinear_weights.append(initializer.initialize_multiresidual(self.nonlinear_dim, self.nonlinear_dim))\n",
    "\n",
    "        self.head_weights = initializer.initialize_head()\n",
    "        self.mask_weights = initializer.initialize_linear(\n",
    "            [1, 0, 0, 1, 0], [self.channel_dim_fn([1, 0, 0, 1, 0]), 2]\n",
    "        )\n",
    "\n",
    "        # Symmetrize weights so that their behavior is equivariant to swapping x and y dimension ordering\n",
    "        for weight_list in [\n",
    "            self.share_up_weights,\n",
    "            self.share_down_weights,\n",
    "            self.softmax_weights,\n",
    "            self.cummax_weights,\n",
    "            self.shift_weights,\n",
    "            self.nonlinear_weights,\n",
    "        ]:\n",
    "            for layer_num in range(self.n_layers):\n",
    "                initializer.symmetrize_xy(weight_list[layer_num])\n",
    "\n",
    "        for layer_num in range(self.n_layers):\n",
    "            initializer.symmetrize_direction_sharing(self.direction_share_weights[layer_num])\n",
    "\n",
    "        self.weights_list = initializer.weights_list\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Compute forward pass of VAE decoder. Start w/ internally stored latents,\n",
    "        and process => Output an [example, color, x, y, channel] tensor for colors,\n",
    "        and  [example, x, channel] and [example, y, channel] tensor for masks.\n",
    "        Returns:\n",
    "            Tensor: An [example, color, x, y, channel] tensor, where for every example,\n",
    "                    input/output (picked by channel dimension), and every pixel (picked\n",
    "                    by x and y dimensions), we have vector full of logits for that\n",
    "                    pixel being each possible color.\n",
    "            Tensor: An [example, x, channel] tensor, where for every example, input/output\n",
    "                    (picked by channel dimension), and every x, we assign score that\n",
    "                    contributes to likelihood that that index of x dimension is not\n",
    "                    masked out in prediction.\n",
    "            Tensor: An [example, y, channel] tensor, used in same way as above.\n",
    "            list[Tensor]: list of tensors indicating amount of KL contributed by each component\n",
    "                    tensor in layers.decode_latents() step.\n",
    "            list[str]: list of tensor names that correspond to each tensor in aforementioned output.\n",
    "        \"\"\"\n",
    "        #decoding layer\n",
    "        x, KL_amounts, KL_names = layers.decode_latents(\n",
    "            self.target_capacities, self.decode_weights, self.multiposteriors\n",
    "        )\n",
    "\n",
    "        for layer_num in range(self.n_layers):\n",
    "            #multitensor communication layer\n",
    "            x = layers.share_up(x, self.share_up_weights[layer_num])\n",
    "\n",
    "            #softmax layer\n",
    "            x = layers.softmax(x, self.softmax_weights[layer_num], pre_norm=True, post_norm=False, use_bias=False)\n",
    "\n",
    "            #directional layers\n",
    "            x = layers.cummax(\n",
    "                x, self.cummax_weights[layer_num], self.multitensor_system.task.masks,\n",
    "                pre_norm=False, post_norm=True, use_bias=False\n",
    "            )\n",
    "            x = layers.shift(\n",
    "                x, self.shift_weights[layer_num], self.multitensor_system.task.masks,\n",
    "                pre_norm=False, post_norm=True, use_bias=False\n",
    "            )\n",
    "\n",
    "            #directional communication layer\n",
    "            x = layers.direction_share(x, self.direction_share_weights[layer_num], pre_norm=True, use_bias=False)\n",
    "\n",
    "            #nonlinear layer\n",
    "            x = layers.nonlinear(x, self.nonlinear_weights[layer_num], pre_norm=True, post_norm=False, use_bias=False)\n",
    "\n",
    "            #nultitensor communication layer\n",
    "            x = layers.share_down(x, self.share_down_weights[layer_num])\n",
    "\n",
    "            #normalization layer\n",
    "            x = layers.normalize(x)\n",
    "\n",
    "        #linear Heads\n",
    "        output = (\n",
    "            layers.affine(x[[1, 1, 0, 1, 1]], self.head_weights, use_bias=False)\n",
    "            + 100 * self.head_weights[1]\n",
    "        )\n",
    "        x_mask = layers.affine(x[[1, 0, 0, 1, 0]], self.mask_weights, use_bias=True)\n",
    "        y_mask = layers.affine(x[[1, 0, 0, 0, 1]], self.mask_weights, use_bias=True)\n",
    "\n",
    "        #postprocessing\n",
    "        x_mask, y_mask = layers.postprocess_mask(self.multitensor_system.task, x_mask, y_mask)\n",
    "\n",
    "        return output, x_mask, y_mask, KL_amounts, KL_names\n"
   ],
   "id": "59c599b7348c5d80",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.887386Z",
     "start_time": "2025-08-10T21:15:59.866310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ParallelTaskScheduler:\n",
    "    \"\"\"coord exec of mult tasks across CPUs GPUs\n",
    "\n",
    "    scheduler assigns tasks to GPUs by avail memory quotas,\n",
    "    spawns worker process solvers per task, and aggregates memory usage\n",
    "    and solution results\n",
    "    impl greedy scheduling algo similar\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, time_budget_hours: float = 12.0):\n",
    "        self.n_cpus = multiprocessing.cpu_count()\n",
    "        self.n_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
    "        self.time_budget = time_budget_hours * 3600\n",
    "        self.start_time = time.time()\n",
    "        self.end_time = self.start_time + self.time_budget - 300  # reserve small buffer\n",
    "        self.gpu_memory_quotas = self._get_gpu_memory_quotas()\n",
    "        self.task_memory_usage = {}\n",
    "        self.task_time_estimates = {}\n",
    "\n",
    "    def _get_gpu_memory_quotas(self) -> List[float]:\n",
    "        \"\"\"ret list of available memory (in GB) for each GPU\"\"\"\n",
    "        quotas = []\n",
    "        if torch.cuda.is_available():\n",
    "            for i in range(self.n_gpus):\n",
    "                mem_info = torch.cuda.mem_get_info(i)\n",
    "                available_gb = mem_info[0] / (1024**3)\n",
    "                quotas.append(available_gb)\n",
    "        else:\n",
    "            quotas = [8.0]\n",
    "        return quotas\n",
    "\n",
    "    def parallelize_runs(self, tasks: Dict, n_iterations: int,\n",
    "                          verbose: bool = False) -> Tuple[Dict, Dict, float]:\n",
    "        \"\"\"run solver processes for all tasks in parallel given resource limits\"\"\"\n",
    "        n_tasks = len(tasks)\n",
    "        task_names = list(tasks.keys())\n",
    "        gpu_quotas = self.gpu_memory_quotas.copy()\n",
    "        tasks_started = [False] * n_tasks\n",
    "        tasks_finished = [False] * n_tasks\n",
    "        processes = [None] * n_tasks\n",
    "        process_gpu_ids = [None] * n_tasks\n",
    "        with multiprocessing.Manager() as manager:\n",
    "            memory_dict = manager.dict()\n",
    "            solutions_dict = manager.dict()\n",
    "            error_queue = manager.Queue()\n",
    "            t_start = time.time()\n",
    "            while not all(tasks_finished):\n",
    "                if not error_queue.empty():\n",
    "                    error = error_queue.get()\n",
    "                    if verbose:\n",
    "                        print(f\"Error occurred: {error}\")\n",
    "                    raise ValueError(error)\n",
    "                #check finished processes\n",
    "                for i in range(n_tasks):\n",
    "                    if tasks_started[i] and not tasks_finished[i]:\n",
    "                        if processes[i] is not None:\n",
    "                            processes[i].join(timeout=0)\n",
    "                            if not processes[i].is_alive():\n",
    "                                tasks_finished[i] = True\n",
    "                                if process_gpu_ids[i] is not None:\n",
    "                                    task_usage = self.task_memory_usage.get(task_names[i], 1.0)\n",
    "                                    gpu_quotas[process_gpu_ids[i]] += task_usage\n",
    "                                    if verbose:\n",
    "                                        print(f\"{task_names[i]} finished on GPU {process_gpu_ids[i]}\")\n",
    "                #schedule new tasks\n",
    "                for gpu_id in range(self.n_gpus):\n",
    "                    for i in range(n_tasks):\n",
    "                        if tasks_started[i]:\n",
    "                            continue\n",
    "                        task_name = task_names[i]\n",
    "                        task_usage = self.task_memory_usage.get(task_name, 1.0)\n",
    "                        enough_quota = gpu_quotas[gpu_id] >= task_usage\n",
    "                        active_processes = sum(tasks_started) - sum(tasks_finished)\n",
    "                        enough_cpus = active_processes < self.n_cpus\n",
    "                        if enough_quota and enough_cpus:\n",
    "                            gpu_quotas[gpu_id] -= task_usage\n",
    "                            args = (\n",
    "                                task_name,\n",
    "                                tasks[task_name],\n",
    "                                n_iterations,\n",
    "                                gpu_id,\n",
    "                                memory_dict,\n",
    "                                solutions_dict,\n",
    "                                error_queue\n",
    "                            )\n",
    "                            p = multiprocessing.Process(target=self._solve_task_process, args=args)\n",
    "                            p.start()\n",
    "                            processes[i] = p\n",
    "                            tasks_started[i] = True\n",
    "                            process_gpu_ids[i] = gpu_id\n",
    "                            if verbose:\n",
    "                                print(f\"{task_name} started on GPU {gpu_id}\")\n",
    "                time.sleep(0.1)\n",
    "            #convert manager dicts\n",
    "            memory_dict = dict(memory_dict)\n",
    "            solutions_dict = dict(solutions_dict)\n",
    "            time_taken = time.time() - t_start\n",
    "            if verbose:\n",
    "                print(f\"All tasks finished in {time_taken:.2f} seconds\")\n",
    "            return memory_dict, solutions_dict, time_taken\n",
    "\n",
    "    def _solve_task_process(self, task_name: str, task_data: Dict,\n",
    "                             n_iterations: int, gpu_id: int,\n",
    "                             memory_dict: Dict, solutions_dict: Dict,\n",
    "                             error_queue: multiprocessing.Queue):\n",
    "        \"\"\"worker process entry point used by parallelize_runs\"\"\"\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.set_device(gpu_id)\n",
    "            solver = ARCCompressor(device=f\"cuda:{gpu_id}\")\n",
    "            memory_used = solver.estimate_memory_usage(task_name, n_iterations)\n",
    "            memory_dict[task_name] = memory_used\n",
    "            solutions = solver.solve_with_compression(task_name, task_data, n_iterations, gpu_id)\n",
    "            solutions_dict[task_name] = solutions\n",
    "        except Exception as e:\n",
    "            error_queue.put(f\"Error in {task_name}: {str(e)}\")\n",
    "\n",
    "    def profile_tasks(self, tasks: Dict, profile_steps: int = 2) -> Dict:\n",
    "        \"\"\"run short profiling pass to est memory usage per task\"\"\"\n",
    "        memory_dict, _, _ = self.parallelize_runs(tasks, n_iterations=profile_steps, verbose=False)\n",
    "        self.task_memory_usage = memory_dict\n",
    "        sorted_tasks = sorted(memory_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        return dict(sorted_tasks)\n",
    "\n",
    "    def estimate_time_per_step(self, tasks: Dict, test_steps: int = 20) -> float:\n",
    "        \"\"\"est time per iteration by running fixed number of steps\"\"\"\n",
    "        safe_quotas = [q - 6.0 for q in self.gpu_memory_quotas]\n",
    "        original_quotas = self.gpu_memory_quotas.copy()\n",
    "        self.gpu_memory_quotas = safe_quotas\n",
    "        _, _, time_taken = self.parallelize_runs(tasks, n_iterations=test_steps, verbose=False)\n",
    "        self.gpu_memory_quotas = original_quotas\n",
    "        return time_taken / test_steps\n",
    "\n",
    "    def calculate_optimal_steps(self, time_per_step: float) -> int:\n",
    "        \"\"\"comp how many iter fit in remaining time budget\"\"\"\n",
    "        time_left = self.end_time - time.time()\n",
    "        n_steps = int(time_left // time_per_step)\n",
    "        return n_steps"
   ],
   "id": "1a59047a89b4d150",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:15:59.916272Z",
     "start_time": "2025-08-10T21:15:59.899014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#main solver class combines all appr\n",
    "class EnhancedARCSolver:\n",
    "\n",
    "    def __init__(self, use_augmentation: bool = True,\n",
    "                 use_symbolic_search: bool = True,\n",
    "                 use_neural: bool = False,\n",
    "                 use_compressarc: bool = False,\n",
    "                 use_parallel: bool = False,\n",
    "                 time_budget_hours: float = 12.0):\n",
    "        self.visualizer = ARCVisualizer()\n",
    "        self.dsl = DSLOperations()\n",
    "        self.augmenter = DataAugmentation()\n",
    "        self.symbolic_searcher = SymbolicProgramSearch(max_depth=3)\n",
    "        self.use_augmentation = use_augmentation\n",
    "        self.use_symbolic_search = use_symbolic_search\n",
    "        self.use_neural = use_neural\n",
    "        self.use_compressarc = use_compressarc\n",
    "        self.use_parallel = use_parallel\n",
    "        if self.use_neural:\n",
    "            self.neural_model = SimpleARCNet()\n",
    "        if self.use_compressarc:\n",
    "            self.compress_solver = ARCCompressor()\n",
    "        if self.use_parallel:\n",
    "            self.scheduler = ParallelTaskScheduler(time_budget_hours)\n",
    "\n",
    "    def solve_task(self, task: Dict, task_id: str = None) -> Dict:\n",
    "        \"\"\"attempt to solve single ARC task using enabled strats\"\"\"\n",
    "        solutions = []\n",
    "        method_used = None\n",
    "        #strat 1: CompressARC\n",
    "        if self.use_compressarc and not solutions:\n",
    "            try:\n",
    "                solutions = self.compress_solver.solve_with_compression(\n",
    "                    task_id or \"unknown\", task, n_iterations=100, gpu_id=0)\n",
    "                if solutions and len(solutions) == len(task[\"test\"]):\n",
    "                    method_used = \"compressarc\"\n",
    "                    print(f\"Solved {task_id} using CompressARC method\")\n",
    "            except Exception as e:\n",
    "                print(f\"CompressARC failed for {task_id}: {e}\")\n",
    "                solutions = []\n",
    "        #strat 2: symbolic search\n",
    "        if self.use_symbolic_search and not solutions:\n",
    "            program = self.symbolic_searcher.search(task)\n",
    "            if program:\n",
    "                print(f\"Found symbolic program for {task_id}: {[p[0] for p in program]}\")\n",
    "                for test in task[\"test\"]:\n",
    "                    result = self.symbolic_searcher.apply(np.array(test[\"input\"]), program)\n",
    "                    if result is not None:\n",
    "                        solutions.append(result.tolist())\n",
    "                if len(solutions) == len(task[\"test\"]):\n",
    "                    method_used = \"symbolic\"\n",
    "        #strat 3: augmentation + search\n",
    "        if self.use_augmentation and not solutions:\n",
    "            augmented_tasks = self.augmenter.augment_task(task)\n",
    "            for aug_task in augmented_tasks:\n",
    "                program = self.symbolic_searcher.search(aug_task)\n",
    "                if program:\n",
    "                    print(f\"Found program w/ augmentation for {task_id}\")\n",
    "                    for test in task[\"test\"]:\n",
    "                        result = np.array(test[\"input\"])\n",
    "                        solutions.append(result.tolist())\n",
    "                    method_used = \"augmented\"\n",
    "                    break\n",
    "        #strat 4: fallback copy\n",
    "        if not solutions:\n",
    "            print(f\"Using fallback for {task_id}\")\n",
    "            for test in task[\"test\"]:\n",
    "                solutions.append(test[\"input\"])\n",
    "            method_used = \"fallback\"\n",
    "        return {\"predictions\": solutions, \"method\": method_used}\n",
    "\n",
    "    def visualize_solution(self, task: Dict, solutions: List,\n",
    "                           task_id: str = None, save_path: str = None):\n",
    "        \"\"\"displ task alongside its soln using matplotlib\"\"\"\n",
    "        fig = self.visualizer.visualize_task_matplotlib(task, task_id, show_predictions=solutions)\n",
    "        if save_path:\n",
    "            fig.savefig(save_path, dpi=100, bbox_inches=\"tight\")\n",
    "        return fig\n",
    "\n",
    "    def export_solution_images(self, task: Dict, solutions: List,\n",
    "                               output_dir: str, task_id: str):\n",
    "        \"\"\"write composite and indiv solution images to disk\"\"\"\n",
    "        output_path = Path(output_dir) / task_id\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        composite = self.visualizer.create_composite_image(task, task_id, solutions)\n",
    "        composite.save(output_path / f\"{task_id}_composite.png\")\n",
    "        for i, solution in enumerate(solutions):\n",
    "            img = self.visualizer.grid_to_image(solution, f\"Test {i+1} Solution\")\n",
    "            img.save(output_path / f\"{task_id}_test{i+1}_solution.png\")\n",
    "\n",
    "    def process_dataset(self, challenges_path: str,\n",
    "                        output_dir: str = \"./arc_output\",\n",
    "                        save_visualizations: bool = True,\n",
    "                        optimize_for_competition: bool = False) -> Dict:\n",
    "        \"\"\"Solve all tasks in specified JSON file and save results\"\"\"\n",
    "        with open(challenges_path, \"r\") as f:\n",
    "            challenges = json.load(f)\n",
    "        all_solutions = {}\n",
    "        if self.use_parallel and optimize_for_competition:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"Running in competition mode w/ parallel processing\")\n",
    "            print(f\"CPUs: {self.scheduler.n_cpus}, GPUs: {self.scheduler.n_gpus}\")\n",
    "            print(f\"Time budget: {self.scheduler.time_budget/3600:.1f} hours\")\n",
    "            print(\"=\" * 60)\n",
    "            sorted_tasks = self.scheduler.profile_tasks(challenges, profile_steps=2)\n",
    "            time_per_step = self.scheduler.estimate_time_per_step(challenges, test_steps=10 if len(challenges) > 10 else 2)\n",
    "            n_steps = self.scheduler.calculate_optimal_steps(time_per_step)\n",
    "            n_steps = min(n_steps, 2500)\n",
    "            print(f\"Running {n_steps} steps per task...\")\n",
    "            _, solutions_dict, time_taken = self.scheduler.parallelize_runs(challenges, n_iterations=n_steps, verbose=True)\n",
    "            for task_id, solutions in solutions_dict.items():\n",
    "                all_solutions[task_id] = solutions\n",
    "            print(f\"Completed in {time_taken/3600:.2f} hours\")\n",
    "            print(f\"Tasks solved: {len(all_solutions)}\")\n",
    "            print(f\"Average steps per task: {n_steps}\")\n",
    "        else:\n",
    "            for task_id, task in challenges.items():\n",
    "                print(f\"Processing task: {task_id}\")\n",
    "                result = self.solve_task(task, task_id)\n",
    "                all_solutions[task_id] = result[\"predictions\"]\n",
    "                if save_visualizations:\n",
    "                    self.export_solution_images(task, result[\"predictions\"], output_dir, task_id)\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        with open(output_path / \"solutions.json\", \"w\") as f:\n",
    "            json.dump(all_solutions, f, indent=2)\n",
    "        return all_solutions"
   ],
   "id": "d22b962dbb58f3a5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T21:16:00.286416Z",
     "start_time": "2025-08-10T21:15:59.930466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def get_gpu_memory_info(gpu_id: int = 0) -> Dict[str, float]:\n",
    "    \"\"\"ret detailed memory information for GPU\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return {\"available\": 0, \"total\": 0, \"used\": 0, \"free\": 0}\n",
    "    mem_info = torch.cuda.mem_get_info(gpu_id)\n",
    "    total = mem_info[1] / (1024**3)\n",
    "    available = mem_info[0] / (1024**3)\n",
    "    used = total - available\n",
    "    return {\n",
    "        \"available\": available,\n",
    "        \"total\": total,\n",
    "        \"used\": used,\n",
    "        \"free\": available,\n",
    "        \"gpu_name\": torch.cuda.get_device_name(gpu_id)\n",
    "    }\n",
    "\n",
    "def print_system_info():\n",
    "    \"\"\"print CPU and GPU config information\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"System information\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"CPUs: {multiprocessing.cpu_count()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        n_gpus = torch.cuda.device_count()\n",
    "        print(f\"GPUs: {n_gpus}\")\n",
    "        for i in range(n_gpus):\n",
    "            info = get_gpu_memory_info(i)\n",
    "            print(f\"  GPU {i}: {info['gpu_name']}\")\n",
    "            print(f\"    Memory: {info['used']:.1f}/{info['total']:.1f} GB used\")\n",
    "    else:\n",
    "        print(\"GPUs: None (CPU mode)\")\n",
    "    print(f\"PyTorch: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"entry when running script as standalone program\"\"\"\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description=\"Enhanced ARC‑AGI2 solver and visualizer\")\n",
    "    parser.add_argument(\"--challenges\", type=str, required=True, help=\"Path to challenges JSON file\")\n",
    "    parser.add_argument(\"--output\", type=str, default=\"./arc_output\", help=\"Output directory for results\")\n",
    "    parser.add_argument(\"--visualize\", action=\"store_true\", help=\"Save visualization images\")\n",
    "    parser.add_argument(\"--no‑augmentation\", action=\"store_true\", help=\"Disable data augmentation\")\n",
    "    parser.add_argument(\"--no‑symbolic\", action=\"store_true\", help=\"Disable symbolic search\")\n",
    "    parser.add_argument(\"--use‑compressarc\", action=\"store_true\", help=\"Enable CompressARC neural method\")\n",
    "    parser.add_argument(\"--parallel\", action=\"store_true\", help=\"Enable parallel GPU processing\")\n",
    "    parser.add_argument(\"--competition‑mode\", action=\"store_true\", help=\"Run w/ all optimizations for competition\")\n",
    "    parser.add_argument(\"--time‑budget\", type=float, default=12.0, help=\"Time budget in hours\")\n",
    "    parser.add_argument(\"--system‑info\", action=\"store_true\", help=\"Print system information\")\n",
    "    args = parser.parse_args()\n",
    "    if args.system_info or args.competition_mode:\n",
    "        print_system_info()\n",
    "    if args.competition_mode:\n",
    "        print(\"\\nCompetition mode enabled\")\n",
    "        print(\"Enabling: CompressARC, parallel processing, all optimizations\")\n",
    "        args.use_compressarc = True\n",
    "        args.parallel = True\n",
    "    solver = EnhancedARCSolver(\n",
    "        use_augmentation=not args.no_augmentation,\n",
    "        use_symbolic_search=not args.no_symbolic,\n",
    "        use_neural=False,\n",
    "        use_compressarc=args.use_compressarc,\n",
    "        use_parallel=args.parallel,\n",
    "        time_budget_hours=args.time_budget\n",
    "    )\n",
    "    solutions = solver.process_dataset(\n",
    "        args.challenges,\n",
    "        args.output,\n",
    "        save_visualizations=args.visualize,\n",
    "        optimize_for_competition=args.competition_mode or args.parallel\n",
    "    )\n",
    "    print(f\"\\nProcessed {len(solutions)} tasks\")\n",
    "    print(f\"Results saved to: {args.output}\")\n",
    "    #create Kaggle submission format\n",
    "    submission = {}\n",
    "    for task_id, task_solutions in solutions.items():\n",
    "        submission[task_id] = []\n",
    "        if isinstance(task_solutions, list) and len(task_solutions) > 0:\n",
    "            if isinstance(task_solutions[0], list):\n",
    "                for solution in task_solutions:\n",
    "                    submission[task_id].append({\n",
    "                        \"attempt_1\": solution,\n",
    "                        \"attempt_2\": solution\n",
    "                    })\n",
    "            else:\n",
    "                submission[task_id].append({\n",
    "                    \"attempt_1\": task_solutions,\n",
    "                    \"attempt_2\": task_solutions\n",
    "                })\n",
    "    with open(Path(args.output) / \"submission.json\", \"w\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    print(\"Submission file created: submission.json\")\n",
    "    if args.competition_mode or args.parallel:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Performance summary\")\n",
    "        print(\"=\" * 60)\n",
    "        if hasattr(solver, \"scheduler\"):\n",
    "            elapsed = time.time() - solver.scheduler.start_time\n",
    "            print(f\"Total time: {elapsed/3600:.2f} hours\")\n",
    "            print(f\"Tasks completed: {len(solutions)}\")\n",
    "            if len(solutions) > 0:\n",
    "                print(f\"Average time per task: {elapsed/len(solutions):.2f} seconds\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #on some systems using CUDA spawn start method is necessary\n",
    "    if torch.cuda.is_available():\n",
    "        multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "    main()"
   ],
   "id": "9b964e483a89ddb0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --challenges CHALLENGES [--output OUTPUT]\n",
      "                             [--visualize] [--no‑augmentation] [--no‑symbolic]\n",
      "                             [--use‑compressarc] [--parallel]\n",
      "                             [--competition‑mode] [--time‑budget TIME‑BUDGET]\n",
      "                             [--system‑info]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --challenges\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 2\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d4d0ab2fde55e03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d607255b8d50e6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
